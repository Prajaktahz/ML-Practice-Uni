{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prajaktahz/ML-Practice-Uni/blob/main/Practical_7_(sklearn_version)_Variable_Importance_%26_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIXDYUwuOKsn"
      },
      "source": [
        "![alt text](http://www.cs.nott.ac.uk/~pszgss/teaching/nlab.png)\n",
        "<h1 style=\"text-align: center;\">ML Practical: Variable Importance & Feature Selection</h1>\n",
        "\n",
        "**At the end of this practical you should be able to:**\n",
        "1. Compute variable importance measures using both *filter* and *permutation importance* measures and understand the difference\n",
        "2. Perform and understand the difference between different feature selection methods (minimally optimal)\n",
        "\n",
        "The data set for the practical is an **Online News Popularity Data Set** where the task is to predict how many shares an article will get as a binary value (\"low\" or \"high\").\n",
        "\n",
        "## This practical is in two parts. The first part will be done as a demonstration. The second part is for you to do.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdXeNxfmcRDd"
      },
      "source": [
        "# Demo\n",
        "## Demo Part 1: Creating a function to compare and print our variable importances\n",
        "Since we want to compare different methods for computing variable importance we are going to want to print them side-by-side ordered by ranking.\n",
        "\n",
        "While we could write the code each time, it gets a bit repeative. So we'll write a function that takes a dictionary of feature_importance scores and the list of feature names and prints the table.\n",
        "\n",
        "*Why a dictionary?* As each list of feature importance scores needs a name, so key = name of method, value = feature importance scores.\n",
        "\n",
        "**You do not have to understand this function for this practical** - just what it does and how to call it. I.e. read the documentation at the top of the function. That said, you should be able to understand it, it only contains python you know/know how to look up. If you've time once you've finished this practical look back of the function and try and understand it. Ask if you have any questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFt5h7bNcXMG"
      },
      "source": [
        "def print_variable_importances( feature_names, dict_in, show_top = 10 ):\n",
        "  \"\"\"\n",
        "  Prints a table of feature importance scores.\n",
        "\n",
        "  Keyword arguments\n",
        "  feature_names -- list of feature names. Must have the same ordering as the\n",
        "                   scores in each instance of list_of_scores (see below)\n",
        "  dict_in       -- dictionary of the form {method_name:list_of_scores} where:\n",
        "                   method_name    -- string\n",
        "                   list_of_scores -- list of scores, ordered in the same order\n",
        "                                     as the passed feature_names\n",
        "  show_top      -- number of features to show (default 10, None to print all)\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Implement the definition of None for show_top\n",
        "  if show_top is None:\n",
        "    show_top = len(feature_names)\n",
        "\n",
        "  # Set up lists to hold the titles and score_feature tuples\n",
        "  # We need a list so that they maintain fixed order as we\n",
        "  # iterate over them row-by-row.\n",
        "  to_print_titles = []\n",
        "  to_print_scores = []\n",
        "\n",
        "  # Pair each list of scores with a copy of the feature names and sort\n",
        "  # based on the variable importance score descending\n",
        "  for k, v in dict_in.items():\n",
        "    # zip pairs, sorted sorts, reverse orders descending\n",
        "    feature_names_plus_scores = sorted( zip(v, feature_names) )\n",
        "    feature_names_plus_scores.reverse()\n",
        "    to_print_titles.append(k)\n",
        "    to_print_scores.append(feature_names_plus_scores)\n",
        "\n",
        "\n",
        "  # Print the scores\n",
        "\n",
        "  # Create a list of strings to print in each header cell\n",
        "  line_parts = []\n",
        "  for j in range(len(to_print_titles)):\n",
        "    line_parts.append('{:<38}'.format(to_print_titles[j]))\n",
        "\n",
        "  # Print each header cell using a separator ' | ', adding the fixed rank column header\n",
        "  print('Rank | ' + ' | '.join( ['{:<38}'.format(x) for x in to_print_titles] ) )\n",
        "\n",
        "  # Print the header underline\n",
        "  print('---- + ' + ' + '.join( [ '-'*38 ]*len(to_print_titles) ) )\n",
        "\n",
        "  # Print each line\n",
        "  for i in range(show_top):\n",
        "    # Create a list of strings to print for each row cell\n",
        "    line_parts = []\n",
        "    for j in range(len(to_print_titles)):\n",
        "      line_parts.append(  '{:<30}: {:.4f}'.format(to_print_scores[j][i][1], to_print_scores[j][i][0]) )\n",
        "    # Print the row by:\n",
        "    # (1) joining each row cell using a separator ' | '\n",
        "    # (2) adding the fixed rank column header\n",
        "    print( '{:<4} | '.format(str(i)) + ' | '.join(line_parts) )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWlhFw_ycBRI"
      },
      "source": [
        "## Demo Part 2: Data loading and create our training and test splits\n",
        "You should be familar with this by now. The data set we will use is has been uploaded to\n",
        "<br>http://www.cs.nott.ac.uk/~pszgss/teaching/OnlineNewsPopularity.csv <br>\n",
        "Full details about the dataset can be found at:\n",
        "<br>https://archive.ics.uci.edu/ml/datasets/online+news+popularity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSee73FGOKss"
      },
      "source": [
        "# Load the data\n",
        "# Check the column names (i.e. print them). What is wrong? Yes, you will need to fix that.\n",
        "# HINT: Strings have a .strip() method which returns the string without any leading or training whitespace.\n",
        "#       I'd advise creating a new (corrected) array of column headings and update data.columns\n",
        "\n",
        "\n",
        "from pandas import read_csv\n",
        "data = read_csv('http://www.cs.nott.ac.uk/~pszgss/teaching/OnlineNewsPopularity.csv')\n",
        "\n",
        "# Fix the column headings\n",
        "new_header = []\n",
        "for x in data.columns:\n",
        "  new_header.append( x.strip() )\n",
        "\n",
        "data.columns = new_header"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty4Ag5cQdyCV",
        "outputId": "c5d45675-1cf7-4c1f-eec7-72e1c8e15dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['url', 'timedelta', 'n_tokens_title', 'n_tokens_content',\n",
              "       'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens',\n",
              "       'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
              "       'average_token_length', 'num_keywords', 'data_channel_is_lifestyle',\n",
              "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
              "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
              "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
              "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
              "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
              "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
              "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
              "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
              "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
              "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
              "       'global_rate_negative_words', 'rate_positive_words',\n",
              "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
              "       'max_positive_polarity', 'avg_negative_polarity',\n",
              "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
              "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
              "       'abs_title_sentiment_polarity', 'shares'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJP9Da7lUQPS",
        "outputId": "9101a4c6-a301-4ed3-ba81-d4a809968e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 url  timedelta  \\\n",
              "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
              "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
              "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
              "\n",
              "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "0            12.0             219.0         0.663594               1.0   \n",
              "1             9.0             255.0         0.604743               1.0   \n",
              "2             9.0             211.0         0.575130               1.0   \n",
              "\n",
              "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
              "0                  0.815385        4.0             2.0       1.0  ...   \n",
              "1                  0.791946        3.0             1.0       1.0  ...   \n",
              "2                  0.663866        3.0             1.0       1.0  ...   \n",
              "\n",
              "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
              "0               0.100000                    0.7              -0.350000   \n",
              "1               0.033333                    0.7              -0.118750   \n",
              "2               0.100000                    1.0              -0.466667   \n",
              "\n",
              "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
              "0                 -0.600              -0.200000                 0.5   \n",
              "1                 -0.125              -0.100000                 0.0   \n",
              "2                 -0.800              -0.133333                 0.0   \n",
              "\n",
              "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
              "0                   -0.1875                     0.0   \n",
              "1                    0.0000                     0.5   \n",
              "2                    0.0000                     0.5   \n",
              "\n",
              "   abs_title_sentiment_polarity  shares  \n",
              "0                        0.1875     593  \n",
              "1                        0.0000     711  \n",
              "2                        0.0000    1500  \n",
              "\n",
              "[3 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dafc95c-13fe-4e2f-92cc-127a7c4518ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>...</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.350000</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.1875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791946</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.118750</td>\n",
              "      <td>-0.125</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dafc95c-13fe-4e2f-92cc-127a7c4518ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dafc95c-13fe-4e2f-92cc-127a7c4518ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dafc95c-13fe-4e2f-92cc-127a7c4518ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c7146f7-7493-4f58-9da9-909dba586328\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c7146f7-7493-4f58-9da9-909dba586328')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c7146f7-7493-4f58-9da9-909dba586328 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmuLZqNigoGH"
      },
      "source": [
        "We now need to select the input and output features.<br>\n",
        "**HINT:** Not all input features should be included.\n",
        "\n",
        "The output feature currently is continuous. Recall that, for this task, we want to predict how many shares an article will get as a binary value (\"low\" or \"high\").\n",
        "\n",
        "* High is defined as shares >= 1400\n",
        "* Low is defined as shares < 1400"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvt6Nw5YfewS"
      },
      "source": [
        "# Select the input and output features\n",
        "# url and timedelta are considered non-predictive in the documentation and\n",
        "# therefore should not be used as an input feature\n",
        "X = data.drop(columns=['url','timedelta','shares'])\n",
        "y = data.shares\n",
        "y.values[y <  1400] = 0\n",
        "y.values[y >=  1400] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUoJwTUhlJqI"
      },
      "source": [
        "Finally we need to split our data into test and training sets.\n",
        "\n",
        "We will perform all feature selection based on the training set ONLY.\n",
        "\n",
        "The test set will be used to test if our feature selection has helped or hurt.\n",
        "\n",
        "Use a `test_size=0.75` and a `random_state=42`.\n",
        "\n",
        "Stratify your sample. There is no need to down or upsample as the sample is approximatly balanced.\n",
        "\n",
        "Why 75% for the test set? As we want the code to execute quickly so you can get more done in the practical. In reality we would not set the test set this high. Once you have complete the practical feel free to change this and see the impact it has."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8DmwoD1lPle"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mGaAAGIcTKV"
      },
      "source": [
        "## Demo Part 3: Removing features with low variance\n",
        "The first thing to do is to check to see if any features (nearly) always have the same value.\n",
        "\n",
        "This is done via a [`VarianceThreshold`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) object. The `VarianceThreshold` Object takes one parameter:\n",
        "* threshold -- the variance threshold below which to remove features\n",
        "\n",
        "`VarianceThreshold` follows the **fit transform** interface and can be used as a pre-processing step within a pipeline.\n",
        "\n",
        "**`.fit(...)`:** Learns which features have low variance.<br>\n",
        "**`.transform(...)`:** Returns a copy of the data removing features with variance below the threshold.\n",
        "\n",
        "After calling `.fit(..)` you can use the:<br>\n",
        "`.get_support()` method to get a boolean mask of which features was selected.\n",
        "\n",
        "Assuming your VarianceThreshold object is called vt, then you can see the list of features that were selected via:<br>\n",
        "`X_train.columns[vt.get_support()]`\n",
        "<br>If you do not understand what that line of code is doing, please ask.\n",
        "\n",
        "**TASKS:**\n",
        "1. Using the methods detailed above write the code to print the selected features with a threshold of zero.\n",
        "2. The function `numpy.invert(...)` will invert a binary mask. Write the code to print the removed features rather than those kept.\n",
        "3. Are any features removed?\n",
        "4. What happens if you change the threshold?\n",
        "5. What would a good value be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuWDcSF4hCp1",
        "outputId": "6597562c-4690-4ff0-93dd-15bb6b664c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "vt = VarianceThreshold(threshold = 0.01)\n",
        "vt.fit(X_train)\n",
        "np.invert( vt.get_support() )\n",
        "\n",
        "X_train.columns[np.invert(vt.get_support())]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['global_sentiment_polarity', 'global_rate_positive_words',\n",
              "       'global_rate_negative_words', 'min_positive_polarity',\n",
              "       'max_negative_polarity'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns[ np.invert(vt.get_support()) ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itRDuCQaz1BE",
        "outputId": "58bacb88-453e-4a3f-e588-06ccac2e56d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['global_sentiment_polarity', 'global_rate_positive_words',\n",
              "       'global_rate_negative_words', 'min_positive_polarity',\n",
              "       'max_negative_polarity'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f0FJwuYlVoJ"
      },
      "source": [
        "## Demo Part 4: Univariate variable importance  (known as filter based methods when used for selection)\n",
        "Features can be ranked by (typically simple) measures of how they **individually** affect the output variable. There are many measures we can use, [a number of them are implemented in sklearn](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection).\n",
        "\n",
        "Univariate feature ranking and selection (all measures) are all implemented in sklearn via the [`GenericUnivariateSelect`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html) object.\n",
        "\n",
        "`GenericUnivariateSelect` follows the **fit transform** interface and can be used as a pre-processing step within a pipeline.\n",
        "\n",
        "**`GenericUnivariateSelect(...)`:** Constructor. Takes parameters which specify which univariate feature importance measure will be calculated (when calling `.fit(...)`) and the strategy to select the \"best\" features for creating a reduced feature dataset (when calling `.transform(...)`). See the documentation for the list of avaliable univariate scoring functions.\n",
        "\n",
        "**`.fit(...)`:** Computes variable importance scores. After calling `.fit(...)` the ranking is avaliable within the object as the attribute `.scores_`<br>\n",
        "\n",
        "**`.transform(...)`:** Takes the input features and creates a new input features dataset (transforms the original dataset into the new dataset) by selecting a subset of the features as defined by the paramters `mode` and `param`. For instance, if the following parameters were passed when creating the GenericUnivariateSelect object (via the cons)  `mode = 'k_best'` and `param = 10`, `.transform(...)` will return a dataset with only the top 10 input features as ranked.\n",
        "\n",
        "If we only want to rank we still set up a selector and call `.fit(..)` to compute the rankings, but simply do not end up selecting features based on it (via `.transform(...)`).\n",
        "\n",
        "After calling `.fit(...)` the scores are available as the attribute: `.scores_`\n",
        "\n",
        "**TASK:**\n",
        "1. First ranking the features via the scoring function: `mutual_info_classif`\n",
        "2. Create a new dataset `X_train_b` by selecting only the top 10 features.\n",
        "3. Unrelated to (1) & (2) create a Pipeline that incorporates kBest features selection via `to mutual_info_classif` where k = 10.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muATkYYAoJ9n"
      },
      "source": [
        "from sklearn.feature_selection import GenericUnivariateSelect, mutual_info_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "498hIBSgXGex",
        "outputId": "02d19a4e-dc3a-4e60-cbdb-a5d6d29a2cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# Demo Task 4.1: First create the GenericUnivariateSelect object, then fit it to compute the scores\n",
        "\n",
        "selector = GenericUnivariateSelect( score_func = mutual_info_classif, mode = 'k_best', param = 10)\n",
        "\n",
        "selector.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenericUnivariateSelect(mode='k_best', param=10,\n",
              "                        score_func=<function mutual_info_classif at 0x7adc245fb640>)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GenericUnivariateSelect(mode=&#x27;k_best&#x27;, param=10,\n",
              "                        score_func=&lt;function mutual_info_classif at 0x7adc245fb640&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GenericUnivariateSelect</label><div class=\"sk-toggleable__content\"><pre>GenericUnivariateSelect(mode=&#x27;k_best&#x27;, param=10,\n",
              "                        score_func=&lt;function mutual_info_classif at 0x7adc245fb640&gt;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(list(zip(selector.scores_,X_train.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV58vN-wNtw8",
        "outputId": "703c6f7e-3d52-483c-d612-25bd6559947e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0, 'abs_title_sentiment_polarity'),\n",
              " (0.0, 'average_token_length'),\n",
              " (0.0, 'avg_positive_polarity'),\n",
              " (0.0, 'data_channel_is_bus'),\n",
              " (0.0, 'data_channel_is_socmed'),\n",
              " (0.0, 'global_sentiment_polarity'),\n",
              " (0.0, 'kw_max_max'),\n",
              " (0.0, 'max_negative_polarity'),\n",
              " (0.0, 'min_positive_polarity'),\n",
              " (0.0, 'n_unique_tokens'),\n",
              " (0.0, 'num_self_hrefs'),\n",
              " (0.0, 'num_videos'),\n",
              " (0.0, 'weekday_is_friday'),\n",
              " (0.0, 'weekday_is_monday'),\n",
              " (0.0, 'weekday_is_thursday'),\n",
              " (0.0, 'weekday_is_tuesday'),\n",
              " (0.0, 'weekday_is_wednesday'),\n",
              " (1.3194129602434046e-05, 'num_keywords'),\n",
              " (0.0003113944678845293, 'title_sentiment_polarity'),\n",
              " (0.0005093956323696247, 'n_non_stop_words'),\n",
              " (0.0006496129606234913, 'n_non_stop_unique_tokens'),\n",
              " (0.0013245570835589415, 'avg_negative_polarity'),\n",
              " (0.0014783433263139134, 'data_channel_is_lifestyle'),\n",
              " (0.00173034695812313, 'global_rate_positive_words'),\n",
              " (0.001835848703227505, 'weekday_is_saturday'),\n",
              " (0.0023183466812881637, 'is_weekend'),\n",
              " (0.002969097120669284, 'n_tokens_content'),\n",
              " (0.0030431957717207414, 'title_subjectivity'),\n",
              " (0.003628020165060253, 'weekday_is_sunday'),\n",
              " (0.0036692002170986004, 'data_channel_is_tech'),\n",
              " (0.003934131167315336, 'num_imgs'),\n",
              " (0.00398667514613571, 'kw_min_min'),\n",
              " (0.004205168896864286, 'abs_title_subjectivity'),\n",
              " (0.004618314833626513, 'rate_positive_words'),\n",
              " (0.0048602097039018854, 'global_rate_negative_words'),\n",
              " (0.006708958812708277, 'rate_negative_words'),\n",
              " (0.006955251017802144, 'data_channel_is_entertainment'),\n",
              " (0.007104094007680528, 'kw_avg_max'),\n",
              " (0.007303966503398707, 'kw_avg_min'),\n",
              " (0.007450469609639354, 'min_negative_polarity'),\n",
              " (0.007933363293133322, 'num_hrefs'),\n",
              " (0.008923724538400846, 'max_positive_polarity'),\n",
              " (0.009976035560845808, 'global_subjectivity'),\n",
              " (0.012549694311076554, 'n_tokens_title'),\n",
              " (0.01713988827688584, 'data_channel_is_world'),\n",
              " (0.018157819496485095, 'kw_min_max'),\n",
              " (0.01936859674171143, 'LDA_01'),\n",
              " (0.021320414786738295, 'kw_max_min'),\n",
              " (0.02149565390978614, 'kw_min_avg'),\n",
              " (0.022202775267819552, 'self_reference_max_shares'),\n",
              " (0.022491839875655284, 'LDA_02'),\n",
              " (0.023962151051237557, 'LDA_04'),\n",
              " (0.02423323809090583, 'LDA_00'),\n",
              " (0.025136970428702332, 'kw_avg_avg'),\n",
              " (0.027572617165172897, 'self_reference_min_shares'),\n",
              " (0.02963283825724483, 'LDA_03'),\n",
              " (0.034010250954167986, 'self_reference_avg_sharess'),\n",
              " (0.038418265314275724, 'kw_max_avg')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOSGibVag1Im",
        "outputId": "d7399efa-2c4d-4c94-cde8-cecd847f757d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We will then add the features and their scores to a dictionary.\n",
        "# We will do this for each scoring method so we can print the comparisons\n",
        "# based on the function written at the start of this practical.\n",
        "# The basic structure for adding to this dictionary and calling the function is\n",
        "# bellow.\n",
        "#\n",
        "# TASK: Fill in the ? to add the computed variable importance scores.\n",
        "\n",
        "feature_importance_scores = {}\n",
        "feature_importance_scores['Filter'] = selector.scores_\n",
        "\n",
        "print_variable_importances( X_train.columns, feature_importance_scores, show_top = 40 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank | Filter                                \n",
            "---- + --------------------------------------\n",
            "0    | kw_max_avg                    : 0.0384\n",
            "1    | self_reference_avg_sharess    : 0.0340\n",
            "2    | LDA_03                        : 0.0296\n",
            "3    | self_reference_min_shares     : 0.0276\n",
            "4    | kw_avg_avg                    : 0.0251\n",
            "5    | LDA_00                        : 0.0242\n",
            "6    | LDA_04                        : 0.0240\n",
            "7    | LDA_02                        : 0.0225\n",
            "8    | self_reference_max_shares     : 0.0222\n",
            "9    | kw_min_avg                    : 0.0215\n",
            "10   | kw_max_min                    : 0.0213\n",
            "11   | LDA_01                        : 0.0194\n",
            "12   | kw_min_max                    : 0.0182\n",
            "13   | data_channel_is_world         : 0.0171\n",
            "14   | n_tokens_title                : 0.0125\n",
            "15   | global_subjectivity           : 0.0100\n",
            "16   | max_positive_polarity         : 0.0089\n",
            "17   | num_hrefs                     : 0.0079\n",
            "18   | min_negative_polarity         : 0.0075\n",
            "19   | kw_avg_min                    : 0.0073\n",
            "20   | kw_avg_max                    : 0.0071\n",
            "21   | data_channel_is_entertainment : 0.0070\n",
            "22   | rate_negative_words           : 0.0067\n",
            "23   | global_rate_negative_words    : 0.0049\n",
            "24   | rate_positive_words           : 0.0046\n",
            "25   | abs_title_subjectivity        : 0.0042\n",
            "26   | kw_min_min                    : 0.0040\n",
            "27   | num_imgs                      : 0.0039\n",
            "28   | data_channel_is_tech          : 0.0037\n",
            "29   | weekday_is_sunday             : 0.0036\n",
            "30   | title_subjectivity            : 0.0030\n",
            "31   | n_tokens_content              : 0.0030\n",
            "32   | is_weekend                    : 0.0023\n",
            "33   | weekday_is_saturday           : 0.0018\n",
            "34   | global_rate_positive_words    : 0.0017\n",
            "35   | data_channel_is_lifestyle     : 0.0015\n",
            "36   | avg_negative_polarity         : 0.0013\n",
            "37   | n_non_stop_unique_tokens      : 0.0006\n",
            "38   | n_non_stop_words              : 0.0005\n",
            "39   | title_sentiment_polarity      : 0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dt022-QiETM"
      },
      "source": [
        "# Demo Task 4.2: Create a new dataset X_train_b by selecting only the top 10 features.\n",
        "X_train_b = selector.transform(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d173CS421dn8",
        "outputId": "a5694e66-f3d0-457e-c6b1-bbd6667e6093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9911, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqMsp8zSjmMr",
        "outputId": "cc29c1d6-e890-4b3e-c56e-17df5109c54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Demo Task 4.3: Unrelated to (1) & (2) create a Pipeline that incorporates kBest features selection via to mutual_info_classif where k = 10.\n",
        "# Terminate the Pipeline with a KNeighborsClassifier\n",
        "# Evaluate the performance of the classifier. Think about other pre-processing steps that might also be useful and include them.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "steps = [('select',StandardScaler()),\n",
        "         ('ss', GenericUnivariateSelect( score_func = mutual_info_classif, mode = 'k_best', param = 10)),\n",
        "         ('model', KNeighborsClassifier())]\n",
        "\n",
        "knn = Pipeline( steps = steps )\n",
        "\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "scores = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5916658258500656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdb3wYGSm9yi",
        "outputId": "91d39645-9c88-4dd0-b22f-8834e14642bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Of course 10 may or may not be the best number to pick. If you feel like it look\n",
        "# back at the scores and try another value.\n",
        "\n",
        "steps = [('select',StandardScaler()),\n",
        "         ('ss', GenericUnivariateSelect( score_func = mutual_info_classif, mode = 'k_best', param = 32)),\n",
        "         ('model', KNeighborsClassifier())]\n",
        "\n",
        "knn = Pipeline( steps = steps )\n",
        "\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "scores = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6095247704570679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLFUK_I-iqw0"
      },
      "source": [
        "# End of Demo. Your turn.\n",
        "## Part 1: Model Based Methods\n",
        "Rather than using external measures of how features **individually** affect the output feature one can rank features by how much they are used in a trained model. An example of this is Random Forests.\n",
        "\n",
        "In sklearn, Random Forests have an attribute `feature_importances_` which stores the scores each feature as a list denoting their importance. These scores are computed when the model is fit.\n",
        "\n",
        "**TASK:**\n",
        "1. Train a RandomForestClassifier and print out a list of feature importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvCuSAcxU_MX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaf2aed-a982-4d1a-fc51-e53651eb96e3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0162212 , 0.02476212, 0.0253116 , 0.00011973, 0.02578386,\n",
              "       0.02148413, 0.01326849, 0.01485121, 0.00816438, 0.02557019,\n",
              "       0.01134817, 0.00172072, 0.00702524, 0.00225036, 0.00293432,\n",
              "       0.00502811, 0.0052196 , 0.00651777, 0.02702512, 0.0298247 ,\n",
              "       0.01613546, 0.00913756, 0.02871362, 0.02184573, 0.04165189,\n",
              "       0.04278875, 0.03103284, 0.02534999, 0.03099166, 0.00298223,\n",
              "       0.00325596, 0.00321724, 0.00304988, 0.003094  , 0.00426773,\n",
              "       0.00265627, 0.0117312 , 0.02779228, 0.02960312, 0.03350304,\n",
              "       0.0269951 , 0.03074201, 0.02741077, 0.02562807, 0.02576137,\n",
              "       0.02276226, 0.02051887, 0.02091801, 0.02409789, 0.01262241,\n",
              "       0.01032296, 0.02395554, 0.01459973, 0.01388344, 0.01282769,\n",
              "       0.01511261, 0.01287966, 0.0117302 ])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_scores['RF'] = rf.feature_importances_\n",
        "\n",
        "print_variable_importances( X_train.columns, feature_importance_scores, show_top = 10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWkRivtpCeP8",
        "outputId": "1eee76ac-3fb4-460c-dbe2-ee69b598ccb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank | Filter                                 | RF                                    \n",
            "---- + -------------------------------------- + --------------------------------------\n",
            "0    | kw_max_avg                    : 0.0384 | kw_avg_avg                    : 0.0428\n",
            "1    | self_reference_avg_sharess    : 0.0340 | kw_max_avg                    : 0.0417\n",
            "2    | LDA_03                        : 0.0296 | LDA_02                        : 0.0335\n",
            "3    | self_reference_min_shares     : 0.0276 | self_reference_min_shares     : 0.0310\n",
            "4    | kw_avg_avg                    : 0.0251 | self_reference_avg_sharess    : 0.0310\n",
            "5    | LDA_00                        : 0.0242 | LDA_04                        : 0.0307\n",
            "6    | LDA_04                        : 0.0240 | kw_avg_min                    : 0.0298\n",
            "7    | LDA_02                        : 0.0225 | LDA_01                        : 0.0296\n",
            "8    | self_reference_max_shares     : 0.0222 | kw_avg_max                    : 0.0287\n",
            "9    | kw_min_avg                    : 0.0215 | LDA_00                        : 0.0278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAgwDC-Hsy90"
      },
      "source": [
        "## Part 2a: Permutation Importance\n",
        "Looking at the feature importance scores from the random forest it is hard to know if we should keep the features or not. Moreover, if we wanted to consider feature importance from, say a non-linear SVM, we couldn't. Therefore we will now consider *permutation importance*.\n",
        "\n",
        "<br>To do this we will use the [sklearn.inspection.permutation_importance](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance).\n",
        "\n",
        "Recall we can either:\n",
        "* compute our permutation importance based on a held-out test set (optionally repeating this multiple times to ensure we didn't hold out an \"easy\" or \"hard\" set by random chance).\n",
        "* compute our permutation importance based on the full dataset after re-training our model on the full dataset (i.e. just before we might use it to predict) (not covered, ask and/or have a go if you're interested!)\n",
        "\n",
        "In either case we're going to use `permutation_importance(...)` function from `sklearn.inspection`. The [documentation is here](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance).\n",
        "\n",
        "\n",
        "The function takes three key arguments:\n",
        "1. A fitted (trained) classifier/regressor\n",
        "2. The input data to compute the permuation importance for\n",
        "3. The output labels to compute the permuation importance for\n",
        "4. Optional paramter: `scoring` - do you want accuracy or something else\n",
        "4. The number of times to repeat the permuation process\n",
        "\n",
        "The function returns a dictionary. Look at the documentation, but mostly you will be interested in the `.importance_means` which is a list of the variable importances (i.e. MDA) for the input variables, in the same order as in the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Computing our permutation importance based on a held-out test set**\n",
        "\n",
        "Basic steps:\n",
        "1. Decide if you are going to select variables based on the variable importance scores or if you are just going to report the results. If you are just going to report the results you can use the test set we've previously made. Otherwise you need to further split the data into a sub_train and validation set as the variable selection should be considered like a \"meta-paramter\".\n",
        "2. Train your model using either you training set or your sub_train set.\n",
        "3. Use the `permutation_importance(...)` function to compute the permutation importance scores.\n",
        "\n",
        "**TASK 2a.1:**\n",
        "Implement a permutation importance based on a held-out test set. Assume we will ONLY REPORT the results.\n",
        "\n",
        "Steps:\n",
        "1. Using the fitted RandomForest model from the previous step use the `permutation_importance(...)` function to compute the permutation importance using the test set. Set n_repeates=3 to speed things up for this exersize.\n",
        "2. In order to interpret the scores it is useful to know what the mean decrease in accuracy (that the feature importance scores represent) have decreased from. Compute the accuracy when using all features (i.e. predict and evaluate the test set).\n",
        "3. Add the feature importances to the results dictionary and print the dictionary to compare the feature importances to those from the previous exercise. These can be accessed from the `.importances_mean` attribute in the returned object."
      ],
      "metadata": {
        "id": "m67XfqJLviX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "perm_imp_results = permutation_importance(rf, X_train, y_train, n_repeats=5)"
      ],
      "metadata": {
        "id": "wldWV_2ExHm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "feature_importance_scores['RF_perm'] = perm_imp_results['importances_mean']\n",
        "\n",
        "print_variable_importances( X_train.columns, feature_importance_scores, show_top = 10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDdPHQS6DECw",
        "outputId": "c2b0e01f-e061-4f9a-edb9-230491f725fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank | Filter                                 | RF                                     | RF_perm                               \n",
            "---- + -------------------------------------- + -------------------------------------- + --------------------------------------\n",
            "0    | kw_max_avg                    : 0.0384 | kw_avg_avg                    : 0.0428 | kw_max_avg                    : 0.0155\n",
            "1    | self_reference_avg_sharess    : 0.0340 | kw_max_avg                    : 0.0417 | kw_avg_avg                    : 0.0076\n",
            "2    | LDA_03                        : 0.0296 | LDA_02                        : 0.0335 | self_reference_min_shares     : 0.0062\n",
            "3    | self_reference_min_shares     : 0.0276 | self_reference_min_shares     : 0.0310 | is_weekend                    : 0.0056\n",
            "4    | kw_avg_avg                    : 0.0251 | self_reference_avg_sharess    : 0.0310 | self_reference_avg_sharess    : 0.0026\n",
            "5    | LDA_00                        : 0.0242 | LDA_04                        : 0.0307 | LDA_02                        : 0.0019\n",
            "6    | LDA_04                        : 0.0240 | kw_avg_min                    : 0.0298 | kw_min_avg                    : 0.0010\n",
            "7    | LDA_02                        : 0.0225 | LDA_01                        : 0.0296 | self_reference_max_shares     : 0.0009\n",
            "8    | self_reference_max_shares     : 0.0222 | kw_avg_max                    : 0.0287 | LDA_04                        : 0.0008\n",
            "9    | kw_min_avg                    : 0.0215 | LDA_00                        : 0.0278 | LDA_01                        : 0.0007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2a.2:**\n",
        "Implement a permutation importance based on a held-out test set. Assume we will THEN DO FEATURE SELECTION.\n",
        "\n",
        "Steps:\n",
        "1. Further split our training set into a subtraining and validation (subtest) set. Use `test_size=0.33, random_state=42`.\n",
        "2. Train a new RandomForest model (on X_train_sub, y_train_sub).\n",
        "2. Using the fitted RandomForest model use the `permutation_importance(...)` function to compute the permutation importance using the validation (subtest) set.\n",
        "2. In order to interpret the scores it is useful to know what the mean decrease in accuracy (that the feature importance scores represent) have decreased from. Compute the accuracy when using all features (i.e. predict and evaluate the test set).\n",
        "3. Add the feature importances to the results dictionary and print the dictionary to compare the feature importances to those from the previous exercise.These can be accessed from the `.importances_mean` attribute in the returned object."
      ],
      "metadata": {
        "id": "FMOR2dFzxH6c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klh4erbgVPi1",
        "outputId": "b02c8618-5c94-4d8d-9a7a-17ae7ad90140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
        "\n",
        "rf_sub = RandomForestClassifier()\n",
        "rf_sub.fit(X_train_sub, y_train_sub)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perm_imp_results_sub = permutation_importance(rf_sub, X_val, y_val, n_repeats=5)\n",
        "\n",
        "# Compute accuracy when using all features on the validation (subtest) set\n",
        "y_pred_val = rf_sub.predict(X_val)\n",
        "accuracy_all_features = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "# Add the feature importances to the results dictionary\n",
        "feature_importance_scores['RF_perm_sub'] = perm_imp_results_sub['importances_mean']\n",
        "\n",
        "# Print the dictionary to compare the feature importances to those from the previous exercise\n",
        "print_variable_importances(X_train.columns, feature_importance_scores, show_top=10)"
      ],
      "metadata": {
        "id": "_xwStii0AwZb",
        "outputId": "e9c3430d-5665-4a81-cdb1-9c7c171ab09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank | Filter                                 | RF                                     | RF_perm                                | RF_perm_sub                           \n",
            "---- + -------------------------------------- + -------------------------------------- + -------------------------------------- + --------------------------------------\n",
            "0    | kw_max_avg                    : 0.0384 | kw_avg_avg                    : 0.0428 | kw_max_avg                    : 0.0155 | kw_avg_avg                    : 0.0119\n",
            "1    | self_reference_avg_sharess    : 0.0340 | kw_max_avg                    : 0.0417 | kw_avg_avg                    : 0.0076 | self_reference_min_shares     : 0.0086\n",
            "2    | LDA_03                        : 0.0296 | LDA_02                        : 0.0335 | self_reference_min_shares     : 0.0062 | self_reference_avg_sharess    : 0.0080\n",
            "3    | self_reference_min_shares     : 0.0276 | self_reference_min_shares     : 0.0310 | is_weekend                    : 0.0056 | is_weekend                    : 0.0066\n",
            "4    | kw_avg_avg                    : 0.0251 | self_reference_avg_sharess    : 0.0310 | self_reference_avg_sharess    : 0.0026 | LDA_02                        : 0.0046\n",
            "5    | LDA_00                        : 0.0242 | LDA_04                        : 0.0307 | LDA_02                        : 0.0019 | data_channel_is_tech          : 0.0044\n",
            "6    | LDA_04                        : 0.0240 | kw_avg_min                    : 0.0298 | kw_min_avg                    : 0.0010 | LDA_04                        : 0.0042\n",
            "7    | LDA_02                        : 0.0225 | LDA_01                        : 0.0296 | self_reference_max_shares     : 0.0009 | global_subjectivity           : 0.0036\n",
            "8    | self_reference_max_shares     : 0.0222 | kw_avg_max                    : 0.0287 | LDA_04                        : 0.0008 | kw_max_avg                    : 0.0035\n",
            "9    | kw_min_avg                    : 0.0215 | LDA_00                        : 0.0278 | LDA_01                        : 0.0007 | kw_max_min                    : 0.0032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2a.3:**\n",
        "Implement a permutation importance based on a held-out test set. Assume we will THEN DO FEATURE SELECTION. Repeat the held-out split using a KFold cv stratergy. Use `sklearn.model_selection.StratifiedKFold` to do this. To keep things simple use k=5.\n",
        "\n",
        "As a final step add the feature importances to the results dictionary and print the dictionary to compare the feature importances to those from the previous exercise."
      ],
      "metadata": {
        "id": "uGXLdXQp4c8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "# Split the training data into subtraining and validation (subtest) sets\n",
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
        "\n",
        "# Initialize a Random Forest Classifier\n",
        "rf_sub = RandomForestClassifier()\n",
        "\n",
        "# Train the Random Forest Classifier on the subtraining set\n",
        "rf_sub.fit(X_train_sub, y_train_sub)"
      ],
      "metadata": {
        "id": "2G6lKIzF4vlm",
        "outputId": "3cd95349-e9c9-42b9-8704-9d61206868fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute permutation importance on the validation (subtest) set\n",
        "perm_imp_results_sub = permutation_importance(rf_sub, X_val, y_val, n_repeats=5, random_state=42)"
      ],
      "metadata": {
        "id": "jx9l-D20dQV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy when using all features on the validation (subtest) set\n",
        "y_pred_val = rf_sub.predict(X_val)\n",
        "accuracy_all_features = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "# Add the feature importances to the results dictionary\n",
        "feature_importance_scores['RF_perm_sub'] = perm_imp_results_sub['importances_mean']\n",
        "\n",
        "# Print the dictionary to compare the feature importances to those from the previous exercise\n",
        "print_variable_importances(X_train.columns, feature_importance_scores, show_top=10)"
      ],
      "metadata": {
        "id": "5Ugb9W6pR-zU",
        "outputId": "01ca6fdf-4e27-475a-e6c9-f47fd135082e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank | Filter                                 | RF                                     | RF_perm                                | RF_perm_sub                           \n",
            "---- + -------------------------------------- + -------------------------------------- + -------------------------------------- + --------------------------------------\n",
            "0    | kw_max_avg                    : 0.0384 | kw_avg_avg                    : 0.0428 | kw_max_avg                    : 0.0155 | kw_avg_avg                    : 0.0166\n",
            "1    | self_reference_avg_sharess    : 0.0340 | kw_max_avg                    : 0.0417 | kw_avg_avg                    : 0.0076 | is_weekend                    : 0.0097\n",
            "2    | LDA_03                        : 0.0296 | LDA_02                        : 0.0335 | self_reference_min_shares     : 0.0062 | self_reference_avg_sharess    : 0.0064\n",
            "3    | self_reference_min_shares     : 0.0276 | self_reference_min_shares     : 0.0310 | is_weekend                    : 0.0056 | self_reference_min_shares     : 0.0062\n",
            "4    | kw_avg_avg                    : 0.0251 | self_reference_avg_sharess    : 0.0310 | self_reference_avg_sharess    : 0.0026 | kw_max_avg                    : 0.0052\n",
            "5    | LDA_00                        : 0.0242 | LDA_04                        : 0.0307 | LDA_02                        : 0.0019 | LDA_02                        : 0.0041\n",
            "6    | LDA_04                        : 0.0240 | kw_avg_min                    : 0.0298 | kw_min_avg                    : 0.0010 | min_negative_polarity         : 0.0034\n",
            "7    | LDA_02                        : 0.0225 | LDA_01                        : 0.0296 | self_reference_max_shares     : 0.0009 | data_channel_is_world         : 0.0033\n",
            "8    | self_reference_max_shares     : 0.0222 | kw_avg_max                    : 0.0287 | LDA_04                        : 0.0008 | num_hrefs                     : 0.0032\n",
            "9    | kw_min_avg                    : 0.0215 | LDA_00                        : 0.0278 | LDA_01                        : 0.0007 | self_reference_max_shares     : 0.0032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5uJjwyjlcKt"
      },
      "source": [
        "### Part 2: Questions\n",
        "Looking at the results what do you notice?\n",
        "\n",
        "Specifically consider the permutation importance scores remembering their interpretation.\n",
        "\n",
        "Try summing the features, what do you notice?\n",
        "\n",
        "What can we infer from this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab0lkQuKm42s"
      },
      "source": [
        "'''High consistency across different importance measures. Discrepancies between importance measures may suggest areas for further investigation.\n",
        "For example, if a feature ranks high in RF but low in permutation importance, it might indicate that the feature is overfitting the model.\n",
        "Features with consistently high importance scores across different methods are likely to be strong predictors and can be prioritized for further analysis or feature engineering.\n",
        "Features with low consistency or inconsistent rankings may require additional scrutiny and possibly reevaluation of their relevance or representation.'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxnrruaRuH6k"
      },
      "source": [
        "## Part 3: Wrapper Methods\n",
        "We know that considering the effect of holding out variables and/or their relative use within a given model does not show how *predictive* they actually are. This is because other variables may share information and other interaction effects may be going on.<br>\n",
        "\n",
        "**Example:** If predicting someones country of birth the feature `country_of_drivers_licence` may not be listed as that predictive as it should have been if the feature `passport_country` exists since the model could have used either in a model dependent way. In random forests they are used equally meaning the predictive amount will be half of what it should have been on average in this case).\n",
        "\n",
        "Wrapper methods perform feature subset search to try and find an optimal subset of features. Typically this is done for **feature selection** rather than **feature understanding**.\n",
        "\n",
        "In the former we are interested in finding a fixed (or minimal) subset of features with the most predictive power. In the latter we are interested in asking questions regarding specific features (or groups of features) and how they individually and in combination with other features affect prediction accuracy. Here we are only going to consider the former. The latter currently must be done manually by holding out variables, writing your own permutation code or using R. See the lecture for more details.\n",
        "\n",
        "\n",
        "### Part 3a: Recursive feature elimination (RFE)\n",
        "Note that, in a lot of cases people will manually recursively eliminate features by running code similar to what we've seen in this practical and then remove features and try again. Why? As it (1) gives more control and (2) as with large datasets we may want to check things each iteration to prevent wasting compute time.\n",
        "\n",
        "However, if we want to automate this, we can use an sklearn RFE Object.\n",
        "\n",
        "In sklearn the RFE Object wraps a model. The model must produce `.feature_importances_` as part of the `.fit(...)` method or another attribute that contains the importances (specified via the `importance_getter` parameter).\n",
        "\n",
        "Unfortunately, the `sklearn.inspection.permutation_importance` is a function that is separate to almost all models `.fit(..)` method. We therefore use a trick. We **change the definition of the .fit(..) method for the classifier/regressor of interest**.\n",
        "\n",
        "The function below will do this for you, **resulting in the permutation importance scores being stored in `feature_importances_perm_`**.\n",
        "\n",
        "The function modifies in-place an estimator **definition**. Use it like:\n",
        "```\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "add_or_remove_permutation_importance(RandomForestClassifier)\n",
        "```\n",
        "\n",
        "Then go on to use rf as the estimator in the sklearn RFE Object. **Do not forget to set the `feature_importances_perm_` parameter**, otherwise the model based importance, rather than permutation importance, scores will be used.\n",
        "\n",
        "At the end, in addition to the attributes from the RFE Object"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_or_remove_permutation_importance( estimator, test_size = 0.33, random_state = 42, n_repeats = 5, save_performance_scores = True ):\n",
        "    '''\n",
        "    Modifies (or removes the modification if it exists) an sklearn estimator class .fit(..) to compute\n",
        "    Permutation Importance based on a test set after fitting. The data passed to the fit function is\n",
        "    first split into a training and test set, then the model trained and PI computed using the test set.\n",
        "\n",
        "            Parameters:\n",
        "                    estimator (sklearn estimator class): A class (not an object), such as RandomForestClassifier, RandomForestRegressor\n",
        "                    test_size (float): The size of the (sub)test set size that will be used to computed the permutation importance\n",
        "                    random_state (int): The random state used when the data is split\n",
        "                    n_repeats (int): The number of repeats for the (sklearn) permutation importance function\n",
        "                    save_performance_scores (bool): If True, computes the accuracy (MAE) for the classifier (regressor) on the held-out (sub)test set\n",
        "                                                    and stores it in estimator.permutation_scores\n",
        "\n",
        "            Returns:\n",
        "                    None. The passed estimator class is modified in place.\n",
        "    '''\n",
        "    from sklearn.inspection import permutation_importance\n",
        "    # define a new fit method that splits the data, trains the estimator\n",
        "    # and then computes the\n",
        "    def fit_with_perm(self, X,y,  sample_weight=None):\n",
        "        # The extra permutation step - split the data\n",
        "        X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "        # Now train the model\n",
        "        self.fit_orig(X_train_sub,y_train_sub, sample_weight=sample_weight)\n",
        "        # compute the feature importance on the test set and set the\n",
        "        # expected attribute for the RFE Object\n",
        "        self.feature_importances_perm_ = permutation_importance(self, X_test_sub, y_test_sub, n_repeats = n_repeats).importances_mean\n",
        "\n",
        "        # If we asked to save the performance scores compute and record them\n",
        "        if save_performance_scores:\n",
        "            # Load a function to check if we have a classifier or regressor so we can use a correct evaluation measure\n",
        "            from sklearn.base import is_classifier\n",
        "            if is_classifier(estimator):\n",
        "                from sklearn.metrics import accuracy_score\n",
        "                estimator.permutation_scores[X.shape[1]] = accuracy_score(y_test_sub,self.predict(X_test_sub))\n",
        "            else:\n",
        "                from sklearn.metrics import mean_absolute_error\n",
        "                estimator.permutation_scores[X.shape[1]] = accuracy_score(y_test_sub,self.predict(X_test_sub))\n",
        "\n",
        "    # if we have previously added the permuatation fit instead\n",
        "    # of the original fit, the estimator will have a fit_orig\n",
        "    # attribute.\n",
        "    if hasattr(estimator, 'fit_orig'):\n",
        "        # if it does, put the .fit method back to the original one\n",
        "        # and remove the dictionary we created to hold permutation scores if requested\n",
        "        estimator.fit = estimator.fit_orig\n",
        "        delattr(estimator, 'fit_orig')\n",
        "        delattr(estimator, 'permutation_scores')\n",
        "        print(\"Estimator's fit method returned to normal.\")\n",
        "    else:\n",
        "        # store the actual fit method so we can (1) call it\n",
        "        # in fit_with_perm(...) and (2) restore it later if we want\n",
        "        estimator.fit_orig = estimator.fit\n",
        "        # assign the estimator's .fit(..) to the new method that includes\n",
        "        # permutation importance\n",
        "        estimator.fit = fit_with_perm\n",
        "        estimator.permutation_scores = {}\n",
        "        print(\"Estimator's fit method set to include permutation importance.\")\n"
      ],
      "metadata": {
        "id": "TelWwF1CJ8ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**TASKS:**\n",
        "1. Create and fit RFE object (model) with and embedded Random Forest Classifier using Permutation Importance. Select 20 features. This will take about 12 minutes to run.\n",
        "2. Print the generated feature importances for the selected features. This information is in the attribute `<rfe_object>.estimator_.permutation_scores`. <br>BONUS: Add a list of all features to the results dictionary with zeros when the feature wasn't selected. [Read the docs.](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
        "3. Print the generated feature importances for the selected features.\n",
        "<br>BONUS: Add a list of all features to the results dictionary with zeros when the feature wasn't selected. [Read the docs.](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
        "4. For each model that was recusivly built with differing numbers of features (from the number of features up to 10) the score of the model was also computed on the held out (sub)test set. This provides an indication of how much predictive performance was lost at we reduced the number of features. View this information via: `<rfe_object>.estimator_.permutation_scores`."
      ],
      "metadata": {
        "id": "EN00VH9OPOrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Create RFE object with embedded Random Forest Classifier\n",
        "rfe = RFE(estimator=rf, n_features_to_select=20)\n",
        "\n",
        "# Fit the RFE object\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Get the names of all features\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = np.where(rfe.support_)[0]\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_features = feature_names[selected_feature_indices]\n",
        "\n",
        "# Print the names of the selected features\n",
        "print(\"Selected Features:\")\n",
        "print(selected_features)"
      ],
      "metadata": {
        "id": "T0RofqaPKV5g",
        "outputId": "842d08d3-82c1-4244-cda3-bd427cb970aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features:\n",
            "Index(['n_tokens_content', 'n_unique_tokens', 'n_non_stop_unique_tokens',\n",
            "       'average_token_length', 'kw_max_min', 'kw_avg_min', 'kw_avg_max',\n",
            "       'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares',\n",
            "       'self_reference_avg_sharess', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03',\n",
            "       'LDA_04', 'global_subjectivity', 'global_sentiment_polarity',\n",
            "       'global_rate_positive_words', 'avg_positive_polarity'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_20 = X_train[selected_features]\n",
        "# Compute permutation importance for all features\n",
        "perm_imp_results = permutation_importance(rfe, X_train, y_train, n_repeats=5, random_state=42)\n",
        "\n",
        "# Print the generated feature importances for all features\n",
        "print(\"Feature Importances:\")\n",
        "print(perm_imp_results.importances_mean)"
      ],
      "metadata": {
        "id": "L-oO5PlBKY2v",
        "outputId": "87c29fd9-a7d0-428e-cc92-2548a599bc3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "[0.         0.00137221 0.00201796 0.         0.00240137 0.\n",
            " 0.         0.         0.         0.00167491 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.00205832 0.00347089 0.         0.         0.00760771 0.\n",
            " 0.04471799 0.03953183 0.02786803 0.         0.02871557 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0062355  0.01430734 0.00962567 0.00649783 0.01434769\n",
            " 0.00417718 0.00458077 0.0017758  0.         0.         0.\n",
            " 0.0008879  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store permutation scores for different numbers of features\n",
        "permutation_scores = {}\n",
        "\n",
        "# Iterate over different numbers of features\n",
        "for n_features in range(1,11):  # From 1 to 10\n",
        "    # Create RFE object with embedded Random Forest Classifier\n",
        "    rfe = RFE(estimator=rf, n_features_to_select=n_features)\n",
        "\n",
        "    # Fit the RFE object\n",
        "    rfe.fit(X_train, y_train)\n",
        "\n",
        "    # Compute permutation importance for the selected features on the test set\n",
        "    perm_imp_results = permutation_importance(rfe, X_test, y_test, n_repeats=2, random_state=42)\n",
        "\n",
        "    # Store the permutation scores for this model\n",
        "    permutation_scores[n_features] = perm_imp_results.importances_mean\n",
        "\n"
      ],
      "metadata": {
        "id": "sJkUzUS5Qd6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the permutation scores for different numbers of features\n",
        "for n_features, scores in permutation_scores.items():\n",
        "    print(f\"Number of features: {n_features}, Permutation Scores: {scores}\")"
      ],
      "metadata": {
        "id": "Wdd5PUCmk1oa",
        "outputId": "e3899a1a-bf9b-40f2-c2fb-899ab19d8562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 1, Permutation Scores: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.02441731 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 2, Permutation Scores: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.0487001  0.02448458 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 3, Permutation Scores: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01890156 0.\n",
            " 0.04336932 0.03398581 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 4, Permutation Scores: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.0186325  0.\n",
            " 0.03010123 0.04446238 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.0202805  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 5, Permutation Scores: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01395756 0.\n",
            " 0.02066727 0.03654189 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01563919 0.02184442 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 6, Permutation Scores: [0.         0.         0.009888   0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.0142098  0.\n",
            " 0.01982646 0.03921569 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.0207009  0.02480409 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 7, Permutation Scores: [0.         0.         0.         0.         0.00808866 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01427707 0.\n",
            " 0.01632866 0.02905862 0.         0.         0.02416507 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.0152356  0.0194565  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 8, Permutation Scores: [0.         0.         0.         0.         0.00618841 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00270743 0.         0.         0.00780278 0.\n",
            " 0.01540376 0.03052164 0.         0.         0.02135674 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01459658 0.01753943 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 9, Permutation Scores: [0.         0.         0.00914808 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0031951  0.         0.         0.00652474 0.\n",
            " 0.01590825 0.03159789 0.         0.         0.02125584 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00877813 0.01067837 0.         0.01170417\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Number of features: 10, Permutation Scores: [0.         0.         0.00835772 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00277469 0.         0.         0.0059698  0.\n",
            " 0.01537013 0.02019641 0.         0.         0.01873339 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00825682 0.01151919 0.         0.00921535\n",
            " 0.00427135 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMB9WsgKlUiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5WE2JTB2Mij"
      },
      "source": [
        "### Part 3b: All relevant feature selection\n",
        "Instead of asking for a fixed number of features, we may simply want to throw away those that are not relevant. This is a more advanced method to **removing features with no/low variance**. I.e. we are looking to throw away features we think do not have any **real** impact. By real impact we mean no significant impact in a generalized sense. While we could have simply defined a threshold for RFE (stopping throwing away features once the permutation importance, i.e. change in mean prediction accuracy, was not zero) we would expect some change in prediction accuracy due to random chance. Addressing this issue the Boruta package finds iteratively throws aways the worst feature of the set, stopping when the change in mean prediction accuracy is greater than chance.\n",
        "\n",
        "**Note: The approach is still a heuristic and may throw away valuable features since it removes features in a greedy fashion. In addition throwing away features now that look like they have no affect may be premature, as your training set grows they may be important.**\n",
        "\n",
        "This is done by wrapping a model (again, one whose `.fit(..)` method produces `.feature_importances_`).\n",
        "\n",
        "**TASKS:**\n",
        "1. Fit a Boruta Object (model) by wrapping a RandomForestClassifier.\n",
        "2. Print the selected features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the permuatation importance step from the fit - otherwise this will\n",
        "# do a lot of compute for no reason and take a very long time!\n",
        "add_or_remove_permutation_importance( RandomForestClassifier )"
      ],
      "metadata": {
        "id": "48IEdzhmlpKt",
        "outputId": "a7037e16-50be-4a8a-a962-8ac1d91ed898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimator's fit method set to include permutation importance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBqFr5g4kcX",
        "outputId": "2aa313d7-ca92-405d-fe4d-bb1e50d9764d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q Boruta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "id": "v8_enGXLXoUO",
        "outputId": "cf15bf16-4a90-4299-8e5b-06e0c89031aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
              "5028              7.0            2874.0         0.298141               1.0   \n",
              "35501            12.0             224.0         0.660633               1.0   \n",
              "\n",
              "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  \\\n",
              "5028                   0.466133       14.0            14.0      25.0   \n",
              "35501                  0.842105        3.0             1.0       1.0   \n",
              "\n",
              "       num_videos  average_token_length  ...  avg_positive_polarity  \\\n",
              "5028          1.0              4.314892  ...               0.398207   \n",
              "35501         1.0              4.629464  ...               0.291667   \n",
              "\n",
              "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
              "5028                0.033333                    1.0              -0.197937   \n",
              "35501               0.100000                    0.6              -0.191667   \n",
              "\n",
              "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
              "5028               -0.700000                  -0.05                0.00   \n",
              "35501              -0.333333                  -0.05                0.05   \n",
              "\n",
              "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
              "5028                        0.0                    0.50   \n",
              "35501                       0.0                    0.45   \n",
              "\n",
              "       abs_title_sentiment_polarity  \n",
              "5028                            0.0  \n",
              "35501                           0.0  \n",
              "\n",
              "[2 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c10db9b-6f9f-4284-ba7e-b11fceb75bf4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>num_videos</th>\n",
              "      <th>average_token_length</th>\n",
              "      <th>...</th>\n",
              "      <th>avg_positive_polarity</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5028</th>\n",
              "      <td>7.0</td>\n",
              "      <td>2874.0</td>\n",
              "      <td>0.298141</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.466133</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.314892</td>\n",
              "      <td>...</td>\n",
              "      <td>0.398207</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.197937</td>\n",
              "      <td>-0.700000</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35501</th>\n",
              "      <td>12.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>0.660633</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.629464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.191667</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c10db9b-6f9f-4284-ba7e-b11fceb75bf4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c10db9b-6f9f-4284-ba7e-b11fceb75bf4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c10db9b-6f9f-4284-ba7e-b11fceb75bf4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0a06aac-cb08-4af5-bbfe-55c15d5d6281\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0a06aac-cb08-4af5-bbfe-55c15d5d6281')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0a06aac-cb08-4af5-bbfe-55c15d5d6281 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMbN4o6A4s6T"
      },
      "source": [
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assuming X_train and y_train are your training data\n",
        "# Create a Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Create Boruta object\n",
        "boruta_selector = BorutaPy(estimator=rf, n_estimators='auto', verbose=2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gymeYk0EKhsJ"
      },
      "source": [
        "Check your predictors performance with all features vs just the features Boruta selected using your test set. Did it make it worse?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjvohemT4s7I"
      },
      "source": [
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assuming X_train and y_train are your training data\n",
        "# Create a Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.int = np.int32\n",
        "np.float = np.float64\n",
        "np.bool = np.bool_"
      ],
      "metadata": {
        "id": "Nn_EXpk4aT1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
        "feat_selector.fit(X_train.values, y_train)"
      ],
      "metadata": {
        "id": "_Ongsbyjox_c",
        "outputId": "cc22aa34-7c1b-4884-ae28-76bbe41a3ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t58\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t42\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t42\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t42\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t42\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t6\n",
            "Rejected: \t42\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t5\n",
            "Rejected: \t43\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t5\n",
            "Rejected: \t43\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t10\n",
            "Tentative: \t5\n",
            "Rejected: \t43\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t4\n",
            "Rejected: \t43\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t4\n",
            "Rejected: \t43\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t11\n",
            "Tentative: \t4\n",
            "Rejected: \t43\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t3\n",
            "Rejected: \t43\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t12\n",
            "Tentative: \t1\n",
            "Rejected: \t45\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t0\n",
            "Rejected: \t45\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t13\n",
            "Tentative: \t0\n",
            "Rejected: \t45\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestClassifier(n_estimators=50,\n",
              "                                          random_state=RandomState(MT19937) at 0x7ADC1E8F5240),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7ADC1E8F5240, verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(n_estimators=50,\n",
              "                                          random_state=RandomState(MT19937) at 0x7ADC1E8F5240),\n",
              "         n_estimators=&#x27;auto&#x27;,\n",
              "         random_state=RandomState(MT19937) at 0x7ADC1E8F5240, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=RandomForestClassifier(n_estimators=50,\n",
              "                                          random_state=RandomState(MT19937) at 0x7ADC1E8F5240),\n",
              "         n_estimators=&#x27;auto&#x27;,\n",
              "         random_state=RandomState(MT19937) at 0x7ADC1E8F5240, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50,\n",
              "                       random_state=RandomState(MT19937) at 0x7ADC1E8F5240)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50,\n",
              "                       random_state=RandomState(MT19937) at 0x7ADC1E8F5240)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( X_train.columns[feat_selector.support_] )"
      ],
      "metadata": {
        "id": "AmTRGaBRWUDg",
        "outputId": "e122020c-34f5-42f3-cbdf-328c8d14a997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['n_unique_tokens', 'n_non_stop_unique_tokens', 'kw_avg_min',\n",
            "       'kw_avg_max', 'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares',\n",
            "       'self_reference_avg_sharess', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_04',\n",
            "       'global_subjectivity'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8J3NQApdWEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}